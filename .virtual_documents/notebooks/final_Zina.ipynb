import pandas as pd
star1_df = pd.read_csv("/Users/ZINA/Desktop/one-star-michelin-restaurants.csv")
star2_df = pd.read_csv("/Users/ZINA/Desktop/two-stars-michelin-restaurants.csv")
star3_df = pd.read_csv("/Users/ZINA/Desktop/three-stars-michelin-restaurants.csv")


# Drop unwanted columns
star1_df.drop(columns=['zipCode'], inplace=True)


star2_df.drop(columns=['zipCode'], inplace=True)


star3_df.drop(columns=['zipCode'], inplace=True)


# Creating a star column
star1_df['stars'] = '1 star'
star2_df['stars'] = '2 stars'
star3_df['stars'] = '3 stars'


# Concatenating the 3 datasets 
stars_df = pd.concat([star1_df, star2_df, star3_df], ignore_index=True)


# Replace $$$$$ with $$$$
stars_df['price'] = stars_df['price'].str.replace('$$$$$', '$$$$', regex=False)


# Clean weird characters
stars_df['price'] = stars_df['price'].str.strip()
stars_df['price'] = stars_df['price'].str.replace(r'\s+', '', regex=True)


# Convert $ to ordinal numbers
stars_df['price_ordinal'] = stars_df['price'].str.count(r'\$')


# Compute median ordinal per star group (1 star, 2 stars, 3 stars)
median_by_star = stars_df.groupby('stars')['price_ordinal'].median().round()


# Replace missing ordinal values using matching star median
stars_df['price_ordinal'] = stars_df['price_ordinal'].fillna(stars_df['stars'].map(median_by_star)).astype(int)


# Now convert back to $ string after filling
stars_df['price'] = stars_df['price_ordinal'].apply(lambda x: '$' * x)


# Define the mapping
price_mean_map = {
    "$": 20,
    "$$": 37.5,
    "$$$": 62.5,
    "$$$$": 100
}


# Create a new column with the mean price
stars_df['price_mean'] = stars_df['price'].map(price_mean_map)


# checking if there are no null values in all price columns 
stars_df.isnull().sum()


# Drop columns
stars_df.drop(columns=['latitude', 'longitude'], inplace=True)
stars_df.head()


#put in lower for joining for example 'creative' with 'Creative'
stars_df["cuisine"] = stars_df["cuisine"].str.strip().str.lower() 


import matplotlib.pyplot as plt
import seaborn as sns

international_types = ["modern cuisine", "classic cuisine",
                       "street food", "meats and grills", "international", "innovative"]

stars_df["cuisine_original"] = stars_df["cuisine"]

stars_df["cuisine"] = stars_df["cuisine"].replace(
    international_types, "international cuisine")

international_sub = stars_df[
    stars_df["cuisine_original"].isin(international_types)]

ax = international_sub["cuisine_original"].value_counts().plot(kind="bar")

plt.title("Distribution of subtypes within international cuisine")
plt.ylabel("Number of restaurants")
plt.xticks(rotation=45, ha="right")

note = ("Modern cuisine combines global flavours with local and seasonal ingredients, ""while innovative refers to more experimental concepts such as molecular ""gastronomy or 3D‑printed food.")

plt.subplots_adjust(bottom=0.3)

plt.figtext(
    0.5,
    0.02,
    note,
    ha="center",
    va="bottom",
    wrap=True,
    fontsize=9
)

plt.show()



stars_df['cuisine'].nunique() #confirm if that values joined


#joining all the food subcategories into a main attribute, in this case "Chinese food" 
chinese_type = ["chinese", 
    "cantonese",
    "cantonese roast meats",
    "dim sum",
    "shanghainese",
    "sichuan",
    "hunanese and sichuan",
    "sichuan-huai yang",
    "fujian",
    "taizhou",
    "hang zhou",
    "noodles and congee"]

stars_df["cuisine"] = stars_df["cuisine"].replace(chinese_type, "chinese")


stars_df['cuisine'].nunique() #confirm if that values joined


#joining all the food subcategories into a main attribute
korean_types = ['korean',
    'korean contemporary',
    'temple cuisine']

stars_df['cuisine'] = stars_df['cuisine'].replace(korean_types, 'korean')


stars_df['cuisine'].nunique() #confirm if that values joined


thai_types = ['thai',
    'thai contemporary',
    'southern thai']

stars_df['cuisine'] = stars_df['cuisine'].replace(thai_types, 'thai')



stars_df['cuisine'].nunique() #confirm if that values joined


american_types = ['american',
    'californian',
    'barbecue',
    'steakhouse']

stars_df['cuisine'] = stars_df['cuisine'].replace(american_types, 'american')



stars_df['cuisine'].nunique() #confirm if that values joined


french_types = ['french',
    'classic french',
    'french contemporary',
    'modern french',
    'creative french']


stars_df['cuisine'] = stars_df['cuisine'].replace(french_types, 'french')



stars_df['cuisine'].nunique() #confirm if that values joined


japanese_types = ['japanese',
    'sushi',
    'teppanyaki',
    'japanese contemporary']

stars_df['cuisine'] = stars_df['cuisine'].replace(japanese_types, 'japanese')



stars_df['cuisine'].nunique() #confirm if that values joined


other_asian_types = ['asian',
    'asian influences',
    'asian contemporary',
    'fusion','taiwanese','peranakan','thai']

stars_df['cuisine'] = stars_df['cuisine'].replace(other_asian_types, 'other asian')



stars_df['cuisine'].nunique() #confirm if that values joined


british_types = ['modern british',
    'traditional british',
    'creative british']

stars_df['cuisine'] = stars_df['cuisine'].replace(british_types, 'british')



stars_df['cuisine'].nunique() #confirm if that values joined


modern_types = ['modern cuisine',
    'modern','modern food']
stars_df['cuisine'] = stars_df['cuisine'].replace(modern_types, 'modern cuisine')


stars_df['cuisine'].nunique() #confirm if that values joined


stars_df['cuisine'].unique() #confirm if that values joined


market_types = ['classic cuisine','market cuisine', 'regional cuisine']
stars_df['cuisine'] = stars_df['cuisine'].replace(market_types, 'classic cuisine')


stars_df['cuisine'].nunique() #confirm if that values joined


mediterranean_types = ['mediterranean', 'mediterranean cuisine']
stars_df['cuisine'] = stars_df['cuisine'].replace(mediterranean_types, 'mediterranean food')


stars_df['cuisine'].unique() #confirm if that values joined


other_european_types = ['european', 'european contemporary','mediterranean food']
stars_df['cuisine'] = stars_df['cuisine'].replace(other_european_types, 'other european')


stars_df['cuisine'].nunique() #confirm if that values joined


italian_types = ['italian', 'italian contemporary']
stars_df['cuisine'] = stars_df['cuisine'].replace(italian_types, 'italian')


stars_df['cuisine'].nunique() #confirm if that values joined


stars_df['cuisine'].nunique() #confirm if that values joined


stars_df['cuisine'].unique()


international_types = ['modern cuisine','classic cuisine', 'street food','meats and grills','international','innovative']
stars_df['cuisine'] = stars_df['cuisine'].replace(international_types, 'international cuisine')


scandinavian_types = ['danish','finnish', 'scandinavian']
stars_df['cuisine'] = stars_df['cuisine'].replace(international_types, 'scandinavian')


stars_df['cuisine'].unique()


stars_df['cuisine'].nunique()


stars_df = stars_df.sort_values(by="price")  
stars_df['price'].unique()


stars_df['name'].nunique()



stars_df.columns


# Restaurant name standardization - lower case

stars_df['name']= stars_df['name'].str.lower()
print (stars_df['name'])


#Trim Excessive Whitespaces:

stars_df['name'] = stars_df['name'].astype(str)
stars_df['name']= stars_df['name'].apply(lambda x: ' '.join(x.split()))

print(stars_df.sample(5)) 


# year check

stars_df['year'].nunique()




print(stars_df['year'])


# city names check
stars_df['city'].nunique()


stars_df['city'].unique()


#Remove Leading/Trailing Spaces

stars_df['city'] = stars_df['city'].str.strip()
print(stars_df['city'])


#convert to lower case

stars_df['city'] = stars_df['city'].str.lower() 
print(stars_df['city'])


#check for duplicates

duplicates = stars_df[stars_df.duplicated(['city'], keep=False)]
print(duplicates)


# order A–Z

#stars_df = stars_df.sort_values(by="city")  
#stars_df['city'].unique()




#remove numbers and zip codes

import re

def clean_city_name(city_name):
    if isinstance(city_name, str):  # Check if the input is a string
        # Use regex to remove " - numbers" at the end of the string
        return re.sub(r'\s-\s\d+$', '', city_name).strip()
    return city_name  # Return as is if it's not a string


stars_df['city'] = stars_df['city'].apply(clean_city_name)


#verify results

print(stars_df['city'].unique())  # Display unique city names to verify the cleaning


#remove special characters 
stars_df['city'] = stars_df['city'].str.replace('/', ' ', regex=False)


stars_df['city'] = stars_df['city'].str.replace('-', ' ', regex=False)


stars_df['city'] = stars_df['city'].str.title()


#the city column are stripped of accents and are presented in ASCII format.

import unidecode
stars_df['city'] = stars_df['city'].astype(str).apply(lambda x: unidecode.unidecode(x))


#verify the results
print(stars_df['city'].unique()) 


#grouping suburbs into major city and add info in a new column 

#create a dictionary 

location_map = {
    # London + neighborhoods
    'north kensington': 'London',
    'kensington': 'London',
    'westminster': 'London',
    'soho': 'London',
    'mayfair': 'London',
    'marylebone': 'London',
    'chelsea': 'London',
    'clapham common': 'London',
    "regent's park": 'London',
    'shoreditch': 'London',
    'spitalfields': 'London',
    'belgravia': 'London',
    'bloomsbury': 'London',
    'finsbury': 'London',
    'fulham': 'London',
    'chiswick': 'London',
    'city centre': 'London',
    'city of london': 'London',
    'hyde park': 'London',
    # San Francisco
    'south san francisco': 'San Francisco',
    # Ireland
    'baile mhic andáin/thomastown': 'Thomastown',
    'gaillimh/galway': 'Galway',
    'cill chainnigh/kilkenny': 'Kilkenny',
    'lios dúin bhearna/lisdoonvarna': 'Lisdoonvarna',
    'athína': 'Athens',
    'ballydehob': 'Ballydehob',
    # Finland
    'helsingfors / helsinki': 'Helsinki',
    # Czech Republic
    'praha': 'Prague',
    # Austria
    'wien': 'Vienna',
    'salzburg': 'Salzburg',
    # Menai Bridge
    'menai bridge/porthaethwy': 'Menai Bridge',
    # USA cities
    'los angeles': 'Los Angeles',
    'san diego': 'San Diego',
    'sacramento': 'Sacramento',
    'new york': 'New York',
    'chicago': 'Chicago',
    'costa mesa': 'Costa Mesa',
    'monterey': 'Monterey',
    'washington, d.c.': 'Washington D.C.',
    'south dalton': 'Dalton',
    # Asia
    'bangkok': 'Bangkok',
    'phuket': 'Phuket',
    'hong kong': 'Hong Kong',
    'taipei': 'Taipei',
    'seoul': 'Seoul',
    'singapore': 'Singapore',
    'macau': 'Macau',
    # Croatia
    'lovran': 'Lovran',
    'rovinj': 'Rovinj',
    'zagreb': 'Zagreb',
    'šibenik': 'Sibenik',
    # Norway / Scandinavia
    'stavanger': 'Stavanger',
    'trondheim': 'Trondheim',
    'oslo': 'Oslo',
    'göteborg': 'Gothenburg',
    'växjö': 'Vaxjo',
    'skåne-tranås': 'Skane-Tranas',
    'vejle': 'Vejle',
    # Denmark
    'fredericia': 'Fredericia',
    'pedersker': 'Pedersker',
    'præstø': 'Praesto',
    # Sweden
    'malmö': 'Malmo',
    'stockholm': 'Stockholm',
    # Portugal / Ireland / UK misc
    'bath': 'Bath',
    'bristol': 'Bristol',
    'cambridge': 'Cambridge',
    'cheltenham': 'Cheltenham',
    'chester': 'Chester',
    'birmingham': 'Birmingham',
    'edinburgh': 'Edinburgh',
    'leeds': 'Leeds',
    'oxford': 'Oxford',
    'stratford-upon-avon': 'Stratford-Upon-Avon',
    'padstow': 'Padstow',
    'torquay': 'Torquay',
    'newcastle upon tyne': 'Newcastle upon Tyne',
    'nottingham': 'Nottingham',
    'bray': 'Bray',
    'bowness-on-windermere': 'Bowness-on-Windermere',
    'cartmel': 'Cartmel',
    'castle combe': 'Castle Combe',
    'chagford': 'Chagford',
    'chew magna': 'Chew Magna',
    'dalry': 'Dalry',
    'dorking': 'Dorking',
    'egham': 'Egham',
    'fence': 'Fence',
    'fordwich': 'Fordwich',
    'grasmere': 'Grasmere',
    'gravetye': 'Gravetye',
    'great milton': 'Great Milton',
    'hallwang': 'Hallwang',
    'hampton in arden': 'Hampton in Arden',
    'harome': 'Harome',
    'henne': 'Henne',
    'horsham': 'Horsham',
    'hunstanton': 'Hunstanton',
    'ilfracombe': 'Ilfracombe',
    'järpen': 'Jarpen',
    'kenilworth': 'Kenilworth',
    'kew': 'Kew',
    'kleinwalsertal': 'Kleinwalsertal',
    'knowstone': 'Knowstone',
    'langho': 'Langho',
    'leith': 'Leith',
    'leynar': 'Leynar',
    'little dunmow': 'Little Dunmow',
    'llanddewi skirrid': 'Llanddewi Skirrid',
    'llandrillo': 'Llandrillo',
    'lovran': 'Lovran',
    'lympstone': 'Lympstone',
    'machynlleth': 'Machynlleth',
    'malmesbury': 'Malmesbury',
    'marlow': 'Marlow',
    'morston': 'Morston',
    'mountsorrel': 'Mountsorrel',
    'murcott': 'Murcott',
    'newbury': 'Newbury',
    'oldstead': 'Oldstead',
    'peat inn': 'Peat Inn',
    'penarth': 'Penarth',
    'port isaac': 'Port Isaac',
    'portscatho': 'Portscatho',
    'ripley': 'Ripley',
    'saint helier/saint-hélier': 'Saint Helier',
    "saint james's": 'Saint James',
    'seasalter': 'Seasalter',
    'shinfield': 'Shinfield',
    'summerhouse': 'Summerhouse',
    'upper hambleton': 'Hambleton',
    'victoria': 'Victoria',
    'wandsworth': 'London',
    'whitebrook': 'Whitebrook',
    'winchester': 'Winchester',
    'winteringham': 'Winteringham'
}

stars_df['major_city'] = stars_df['city'].replace(location_map)


print(stars_df[['city', 'major_city']].sample(10))  


stars_df['name'].unique


stars_df.tail(200)


stars_df.shape


import matplotlib.pyplot as plt
import seaborn as sns

sns.set_theme(style="whitegrid")


stars_df["cuisine"].value_counts().head(10).plot(kind="bar")
plt.title("Top 10 types of cuisine")
plt.xlabel("Cuisine")
plt.ylabel("Nº of restaurants")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()



top_cuisines = (
    stars_df["cuisine"].value_counts()
    .head(10)
    .index
)

plt.figure(figsize=(8,4))
sns.countplot(
    data=stars_df[stars_df["cuisine"].isin(top_cuisines)],
    y="cuisine",
    order=top_cuisines
)
plt.title("Top 10 types of cuisine")
plt.xlabel("Nº of restaurants")
plt.ylabel("Cuisine")
plt.tight_layout()


stars_df["stars_n"] = stars_df["stars"].str[0].astype(int)

stars_df.groupby("region")["stars_n"].mean().sort_values().plot(kind="bar")
plt.title("Mean of Stars per region")
plt.xlabel("Region")
plt.ylabel("Mean of stars")
plt.xticks(rotation=45, ha="right")
plt.tight_layout()




#visuals: 
#which are the cities with more restaurants? 
#which is the city / region with highest 1 star / 2 stars / 3 stars/ 4 stars ?
# which are the cuisine dominating a city /region 
# avg price point in a specific city based on restaurants?
# time series 2018 vs 2019 any trend? any star restautant grew over past year? 
# cheapest vs most expensive cuisine? 



import requests
import time
import numpy as np

API_KEY = "AIzaSyC8VCFpZ1WhNUegfd5ziwZPVRCe1pi35lo"

def get_place_rating(name, city, api_key=API_KEY, sleep_sec=0.2):
    query = f"{name}, {city}"
    url_search = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
    params_search = {
        "input": query,
        "inputtype": "textquery",
        "fields": "place_id",
        "key": api_key
    }
    r = requests.get(url_search, params=params_search)
    data = r.json()
    status = data.get("status")
    print("SEARCH:", query, "->", status)
    if status != "OK":
        return None, None

    place_id = data["candidates"][0]["place_id"]

    url_details = "https://maps.googleapis.com/maps/api/place/details/json"
    params_details = {
        "place_id": place_id,
        "fields": "rating,user_ratings_total",
        "key": api_key
    }
    d = requests.get(url_details, params=params_details)
    det = d.json()
    d_status = det.get("status")
    print("DETAILS:", place_id, "->", d_status)
    if d_status != "OK":
        return None, None

    time.sleep(sleep_sec)
    result = det.get("result", {})
    return result.get("rating"), result.get("user_ratings_total")


# inicializar colunas (se ainda não existirem)
if "Review_rating" not in stars_df.columns:
    stars_df["Review_rating"] = np.nan
if "Review_count" not in stars_df.columns:
    stars_df["Review_count"] = np.nan

# lista de restaurantes (ou partes do nome) que queres atualizar
target_names = ["eleven madison park", "per se", "chef's table at brooklyn fare"]  # podes editar/expandir

for idx, row in stars_df.iterrows():
    name_lower = str(row["name"]).lower()

    # verifica se algum dos nomes alvo aparece no name da linha
    if any(tn.lower() in name_lower for tn in target_names):
        rating, count = get_place_rating(row["name"], row["city"])
        stars_df.at[idx, "Review_rating"] = rating
        stars_df.at[idx, "Review_count"] = count
    # os outros restaurantes ficam como estão (NaN ou valores antigos)





stars_df = stars_df.sort_values(by="name", ascending=True).reset_index(drop=True)


stars_df = stars_df.sort_values(by="name", ascending=True).reset_index(drop=True)
stars_df['name'].unique()


rest_names = ["per se", "eleven madison park","chef's table at brooklyn fare"]

mask = stars_df["name"].str.strip().str.lower().isin(
    [n.strip().lower() for n in rest_names]
)
linha_restaurante = stars_df.loc[mask, :]

print(linha_restaurante)
print(stars_df.loc[mask, "Review_rating"])




stars_df.head(5)


stars_df.columns


import pandas as pd

pd.set_option("display.max_columns", None)  # mostra todas as colunas
stars_df.head()                            # ou stars_df.sample(5)




